{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMS Data Processing\n",
    "### The Data\n",
    "This notebooks serves as a step-by-step explanation of how the deep mutational scanning (DMS) data sets from Bloom lab at Fred Hutch and Starr lab at University of Utah were processed for our machine learning projects. Here, six data sets are utilized from 3 repos:\n",
    "- [SARS-CoV-2-RBD_DMS_variants](https://github.com/jbloomlab/SARS-CoV-2-RBD_DMS_variants), paper: [Shifting mutational constraints in the SARS-CoV-2 receptor-binding domain during viral evolution](https://www.science.org/doi/10.1126/science.abo7896)\n",
    "    - [Binding](https://github.com/jbloomlab/SARS-CoV-2-RBD_DMS_variants/blob/main/results/binding_Kd/bc_binding.csv)\n",
    "    - [Expression](https://github.com/jbloomlab/SARS-CoV-2-RBD_DMS_variants/blob/main/results/expression_meanF/bc_expression.csv)\n",
    "    - Variant backgrounds included:\n",
    "        - Wuhan-Hu-1 background (\"wildtype\")\n",
    "        - N501Y (Alpha, found in the B.1.1.7 lineage)\n",
    "        - K417N+E484K+N501Y (Beta, found in the B.1.351 lineage)\n",
    "        - E484K (Eta, found in the B.1.525 lineage)\n",
    "- [SARS-CoV-2-RBD_Delta](https://github.com/jbloomlab/SARS-CoV-2-RBD_Delta/tree/main)\n",
    "    - [Binding](https://github.com/jbloomlab/SARS-CoV-2-RBD_Delta/blob/main/results/binding_Kd/bc_binding.csv)\n",
    "    - [Expression](https://github.com/jbloomlab/SARS-CoV-2-RBD_Delta/blob/main/results/expression_meanF/bc_expression.csv)\n",
    "    - Variant backgrounds included:\n",
    "        - L452R, T478K (Delta, found in the B.1.617.2 lineage)\n",
    "- [SARS-CoV-2-RBD_DMS_Omicron](https://github.com/jbloomlab/SARS-CoV-2-RBD_DMS_Omicron), paper: [Deep mutational scans for ACE2 binding, RBD expression, and antibody escape in the SARS-CoV-2 Omicron BA.1 and BA.2 receptor-binding domains](https://journals.plos.org/plospathogens/article?id=10.1371/journal.ppat.1010951)\n",
    "    - [Binding](https://github.com/jbloomlab/SARS-CoV-2-RBD_DMS_Omicron/tree/main/results/binding_Kd)\n",
    "    - [Expression](https://github.com/jbloomlab/SARS-CoV-2-RBD_DMS_Omicron/tree/main/results/expression_meanF)\n",
    "    - Variant backgrounds included:\n",
    "        - Wuhan-Hu-1\n",
    "        - Omicron BA.1\n",
    "        - Omicron BA.2\n",
    "- [SARS-CoV-2-RBD_DMS_Omicron-XBB-BQ](https://github.com/tstarrlab/SARS-CoV-2-RBD_DMS_Omicron-XBB-BQ), paper: [Deep mutational scans of XBB.1.5 and BQ.1.1 reveal ongoing epistatic drift during SARS-CoV-2 evolution](https://journals.plos.org/plospathogens/article?id=10.1371/journal.ppat.1011901)\n",
    "    - [Binding](https://github.com/tstarrlab/SARS-CoV-2-RBD_DMS_Omicron-XBB-BQ/tree/main/results/binding_Kd)\n",
    "    - [Expression](https://github.com/tstarrlab/SARS-CoV-2-RBD_DMS_Omicron-XBB-BQ/tree/main/results/expression_meanF)\n",
    "    - Variant backgrounds included:\n",
    "        - Omicron XBB.1.5\n",
    "        - Omicron BQ.1.1\n",
    "\n",
    "--- \n",
    "\n",
    "## Processing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in the data. We'll start with `variants-bc_binding.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>library</th>\n",
       "      <th>barcode</th>\n",
       "      <th>target</th>\n",
       "      <th>variant_class</th>\n",
       "      <th>aa_substitutions</th>\n",
       "      <th>n_aa_substitutions</th>\n",
       "      <th>TiteSeq_avgcount</th>\n",
       "      <th>log10Ka</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pool1A</td>\n",
       "      <td>AAAAAAAAAAAAAGAA</td>\n",
       "      <td>N501Y</td>\n",
       "      <td>1 nonsynonymous</td>\n",
       "      <td>T46Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1.955927</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pool1A</td>\n",
       "      <td>AAAAAAAAAAAGGAGA</td>\n",
       "      <td>Wuhan_Hu_1</td>\n",
       "      <td>1 nonsynonymous</td>\n",
       "      <td>G166M</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pool1A</td>\n",
       "      <td>AAAAAAAAAAATTTAA</td>\n",
       "      <td>Wuhan_Hu_1</td>\n",
       "      <td>wildtype</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>36.004828</td>\n",
       "      <td>8.506648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pool1A</td>\n",
       "      <td>AAAAAAAAAACGCGTA</td>\n",
       "      <td>Wuhan_Hu_1</td>\n",
       "      <td>1 nonsynonymous</td>\n",
       "      <td>E154T</td>\n",
       "      <td>1</td>\n",
       "      <td>26.968699</td>\n",
       "      <td>8.586023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pool1A</td>\n",
       "      <td>AAAAAAAAAACTCCAA</td>\n",
       "      <td>Wuhan_Hu_1</td>\n",
       "      <td>1 nonsynonymous</td>\n",
       "      <td>F156M</td>\n",
       "      <td>1</td>\n",
       "      <td>40.906723</td>\n",
       "      <td>7.698023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520334</th>\n",
       "      <td>pool2A</td>\n",
       "      <td>TTTTTTTACCGCACTA</td>\n",
       "      <td>B1351</td>\n",
       "      <td>1 nonsynonymous</td>\n",
       "      <td>S19T</td>\n",
       "      <td>1</td>\n",
       "      <td>36.790470</td>\n",
       "      <td>8.275822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520335</th>\n",
       "      <td>pool2A</td>\n",
       "      <td>TTTTTTTAGCATTACC</td>\n",
       "      <td>E484K</td>\n",
       "      <td>wildtype</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>98.541470</td>\n",
       "      <td>8.312709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520336</th>\n",
       "      <td>pool2A</td>\n",
       "      <td>TTTTTTTGATATTGGA</td>\n",
       "      <td>Wuhan_Hu_1</td>\n",
       "      <td>1 nonsynonymous</td>\n",
       "      <td>C158G</td>\n",
       "      <td>1</td>\n",
       "      <td>38.976891</td>\n",
       "      <td>5.333362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520337</th>\n",
       "      <td>pool2A</td>\n",
       "      <td>TTTTTTTGGGCATGTA</td>\n",
       "      <td>N501Y</td>\n",
       "      <td>&gt;1 nonsynonymous</td>\n",
       "      <td>P54D L183H</td>\n",
       "      <td>2</td>\n",
       "      <td>5.054723</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520338</th>\n",
       "      <td>pool2A</td>\n",
       "      <td>TTTTTTTGTGATAGGA</td>\n",
       "      <td>E484K</td>\n",
       "      <td>1 nonsynonymous</td>\n",
       "      <td>N151T</td>\n",
       "      <td>1</td>\n",
       "      <td>38.482794</td>\n",
       "      <td>8.406922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520339 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       library           barcode      target     variant_class  \\\n",
       "0       pool1A  AAAAAAAAAAAAAGAA       N501Y   1 nonsynonymous   \n",
       "1       pool1A  AAAAAAAAAAAGGAGA  Wuhan_Hu_1   1 nonsynonymous   \n",
       "2       pool1A  AAAAAAAAAAATTTAA  Wuhan_Hu_1          wildtype   \n",
       "3       pool1A  AAAAAAAAAACGCGTA  Wuhan_Hu_1   1 nonsynonymous   \n",
       "4       pool1A  AAAAAAAAAACTCCAA  Wuhan_Hu_1   1 nonsynonymous   \n",
       "...        ...               ...         ...               ...   \n",
       "520334  pool2A  TTTTTTTACCGCACTA       B1351   1 nonsynonymous   \n",
       "520335  pool2A  TTTTTTTAGCATTACC       E484K          wildtype   \n",
       "520336  pool2A  TTTTTTTGATATTGGA  Wuhan_Hu_1   1 nonsynonymous   \n",
       "520337  pool2A  TTTTTTTGGGCATGTA       N501Y  >1 nonsynonymous   \n",
       "520338  pool2A  TTTTTTTGTGATAGGA       E484K   1 nonsynonymous   \n",
       "\n",
       "       aa_substitutions  n_aa_substitutions  TiteSeq_avgcount   log10Ka  \n",
       "0                  T46Q                   1          1.955927       NaN  \n",
       "1                 G166M                   1          0.000000       NaN  \n",
       "2                   NaN                   0         36.004828  8.506648  \n",
       "3                 E154T                   1         26.968699  8.586023  \n",
       "4                 F156M                   1         40.906723  7.698023  \n",
       "...                 ...                 ...               ...       ...  \n",
       "520334             S19T                   1         36.790470  8.275822  \n",
       "520335              NaN                   0         98.541470  8.312709  \n",
       "520336            C158G                   1         38.976891  5.333362  \n",
       "520337       P54D L183H                   2          5.054723       NaN  \n",
       "520338            N151T                   1         38.482794  8.406922  \n",
       "\n",
       "[520339 rows x 8 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = './data'\n",
    "\n",
    "# Load in .csv\n",
    "variants_binding_csv = os.path.join(data_dir, 'original_dms/variants-bc_binding.csv')\n",
    "variants_binding_df = pd.read_csv(variants_binding_csv, sep=',', header=0)\n",
    "variants_binding_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rename the target column for easier identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_map = {\n",
    "    'N501Y': 'Alpha',\n",
    "    'B1351': 'Beta',\n",
    "    'Delta': 'Delta',\n",
    "    'E484K': 'Eta',\n",
    "    'BA1': 'Omicron_BA1',\n",
    "    'BA2': 'Omicron_BA2',\n",
    "    'BQ11': 'Omicron_BQ11',\n",
    "    'XBB15': 'Omicron_XBB15',\n",
    "    'Wuhan_Hu_1': 'Wuhan_Hu_1'\n",
    "}\n",
    "\n",
    "# Rename target columns for easier variant identification\n",
    "variants_binding_df['target'] = variants_binding_df['target'].replace(rename_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop any NaN values in the column that contains the `log10Ka` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431304\n"
     ]
    }
   ],
   "source": [
    "# Remove rows where specified column is NA/N\n",
    "variants_binding_df = variants_binding_df.dropna(subset=['log10Ka']).reset_index(drop=True)\n",
    "print(len(variants_binding_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how many of each `variant_class` there are. In the end, we want to filter out any variant classes that are not nonsynonymous mutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variant_class\n",
      "1 nonsynonymous     265843\n",
      "wildtype            106281\n",
      ">1 nonsynonymous     57840\n",
      "synonymous            1340\n",
      "Name: count, dtype: int64\n",
      "323683\n"
     ]
    }
   ],
   "source": [
    "# Count number of entries per variant class\n",
    "value_counts = variants_binding_df['variant_class'].value_counts()\n",
    "print(value_counts)\n",
    "\n",
    "# Filter out variant classes that are not nonsynonymous\n",
    "nonsynonymous_df = variants_binding_df[variants_binding_df['variant_class'].str.contains('nonsynonymous', case=False, na=False)]\n",
    "print(len(nonsynonymous_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to acquire the unique nonsynonymous mutations. We create a column called \"label\" that consists of the \"target\" and \"aa_substitutions\" columns to prevent removal of the same substitutions that occurred for different targets. We'll then group by the \"label\" column and calculate the mean of the \"log10Ka\" for each grouping. We'll then merge with the duplicates replaced with the mean \"log10Ka\", and drop any duplicate label values. This leaves us with our unique nonsynonymous mutation data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different variants/targets: ['Wuhan_Hu_1' 'Beta' 'Eta' 'Alpha']\n",
      "\n",
      "label\n",
      "Eta-V115L                 153\n",
      "Eta-N171S                 145\n",
      "Beta-V32L                 135\n",
      "Eta-V115S                 128\n",
      "Eta-V115R                 127\n",
      "                         ... \n",
      "Beta-L131P_D137G            1\n",
      "Wuhan_Hu_1-L57M_N130K       1\n",
      "Beta-G117K_Q168D_C195F      1\n",
      "Eta-Y50R_Y123Q              1\n",
      "Alpha-S19D_Y159H            1\n",
      "Name: count, Length: 52763, dtype: int64\n",
      "\n",
      "52763\n",
      "323683\n",
      "52763\n",
      "Number of unique nonsynonymous mutations: 52763\n"
     ]
    }
   ],
   "source": [
    "nonsynonymous_df = nonsynonymous_df.copy()\n",
    "print(f\"Different variants/targets: {nonsynonymous_df['target'].unique()}\\n\")\n",
    "\n",
    "# Add '_' to aa_substitutions column\n",
    "nonsynonymous_df.loc[:, 'aa_substitutions'] = nonsynonymous_df['aa_substitutions'].replace(' ', '_', regex=True)\n",
    "\n",
    "# Create a new column 'label' using 'target' and 'aa_substitutions' columns\n",
    "nonsynonymous_df['label'] = nonsynonymous_df['target'] + '-' + nonsynonymous_df['aa_substitutions']\n",
    "print(f\"{nonsynonymous_df['label'].value_counts()}\\n\")\n",
    "\n",
    "# Group by 'label' and calculate the mean of the specified value column for each group\n",
    "unique_nonsynonymous_df = nonsynonymous_df.groupby('label', as_index=False)['log10Ka'].mean()\n",
    "print(len(unique_nonsynonymous_df))\n",
    "\n",
    "# Merge dfs, replace duplicate with average\n",
    "merged_df = pd.merge(unique_nonsynonymous_df, nonsynonymous_df.drop(columns='log10Ka'), on='label', how='left')\n",
    "print(len(merged_df))\n",
    "\n",
    "# Drop duplicate rows based on 'label'\n",
    "merged_df = merged_df.drop_duplicates(subset='label').reset_index(drop=True)\n",
    "print(len(merged_df))\n",
    "\n",
    "# Count number of unique nonsynonymous mutations\n",
    "unique_nonsynonymous_mutations_counts = merged_df['label'].nunique()\n",
    "print(f\"Number of unique nonsynonymous mutations: {unique_nonsynonymous_mutations_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to pull the different variant DNA sequences from the `/data` folders in each of the git repos... for example they look like `PacBio_amplicon_*.gb`, where * is the variant. We want to extract the DNA sequences, convert to RNA, then convert to amino acids. We then use each of these amino acid sequences as the reference sequence to apply the `aa_substitutions` to based on the variant, or `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wuhan_Hu_1: NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKST\n",
      "Beta: NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGNIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVKGFNCYFPLQSYGFQPTYGVGYQPYRVVVLSFELLHAPATVCGPKKST\n",
      "Eta: NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVKGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKST\n",
      "Alpha: NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTYGVGYQPYRVVVLSFELLHAPATVCGPKKST\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "def extract_refseqs(variants: list) -> dict:\n",
    "    rename_map = {\n",
    "    'N501Y': 'Alpha',\n",
    "    'B1351': 'Beta',\n",
    "    'Delta': 'Delta',\n",
    "    'E484K': 'Eta',\n",
    "    'BA1': 'Omicron_BA1',\n",
    "    'BA2': 'Omicron_BA2',\n",
    "    'BQ11': 'Omicron_BQ11',\n",
    "    'XBB15': 'Omicron_XBB15',\n",
    "    'Wuhan_Hu_1': 'Wuhan_Hu_1'\n",
    "    }\n",
    "    target_dict = {}\n",
    "\n",
    "    for v in variants:\n",
    "        amplicon = os.path.join(data_dir, f'amplicons/PacBio_amplicon_{v}.gb')\n",
    "\n",
    "        # Extract data from genbank file\n",
    "        data = SeqIO.read(amplicon, 'genbank')\n",
    "\n",
    "        # Get full sequence, features \n",
    "        full_seq = data.seq\n",
    "        features = data.features\n",
    "\n",
    "        # Get locations for the \"gene\", apply to the full sequence\n",
    "        for feature in features:\n",
    "            if feature.type == \"gene\":\n",
    "                dna_seq = feature.location.extract(full_seq)\n",
    "\n",
    "        # Convert DNA to RNA\n",
    "        rna_seq = dna_seq.transcribe()\n",
    "\n",
    "        # Translate RNA to Amino Acids\n",
    "        protein_seq= rna_seq.translate()\n",
    "\n",
    "        # Get the renamed target from the rename_map, default to the original name if not found\n",
    "        renamed_target = rename_map.get(v, v)\n",
    "\n",
    "        # Add to target dictionary with the renamed key\n",
    "        target_dict[renamed_target] = protein_seq\n",
    "    \n",
    "    return target_dict\n",
    "\n",
    "variants = ['Wuhan_Hu_1', 'B1351', 'E484K', 'N501Y']\n",
    "variants_target_refseqs = extract_refseqs(variants)\n",
    "\n",
    "for t in variants_target_refseqs: print(f\"{t}: {variants_target_refseqs[t]}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the reference sequences for each of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_seq(row, target_refseqs:dict) -> str:\n",
    "    \"\"\" Generate sequence based on reference sequence and aa_substitutions. \"\"\"\n",
    "    aa_substitutions, target = row['aa_substitutions'], row['target']\n",
    "    refseq = list(target_refseqs[target])\n",
    "    seq = refseq.copy()\n",
    "    p = '([0-9]+)'\n",
    "    \n",
    "    if '_' in aa_substitutions:\n",
    "        for mutcode in aa_substitutions.split('_'):\n",
    "            [ori, pos, mut] = re.split(p, mutcode)\n",
    "            pos = int(pos)-1    # use 0-based counting\n",
    "            #assert refseq[pos].upper() == ori, f\"At {pos}: {refseq[pos]} != {ori}\"\n",
    "            if refseq[pos].upper() != ori: print(f\"{target}, At {pos}: {refseq[pos]} != {ori}\")\n",
    "            seq[pos] = mut.upper()\n",
    "        seq = ''.join(seq)\n",
    "        return seq\n",
    "\n",
    "    if aa_substitutions=='': return ''.join(seq)\n",
    "\n",
    "    [ori, pos, mut] = re.split(p, aa_substitutions)\n",
    "    pos = int(pos)-1    # use 0-based counting\n",
    "    #assert refseq[pos].upper() == ori, f\"At {pos}: {refseq[pos]} != {ori}\"\n",
    "    if refseq[pos].upper() != ori: print(f\"{target}, At {pos}: {refseq[pos]} != {ori}\")\n",
    "    seq[pos] = mut.upper()\n",
    "    seq = ''.join(seq)    \n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "      <th>aa_substitutions</th>\n",
       "      <th>log10Ka</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alpha-A105C</td>\n",
       "      <td>Alpha</td>\n",
       "      <td>A105C</td>\n",
       "      <td>9.086811</td>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alpha-A105C_G196Q</td>\n",
       "      <td>Alpha</td>\n",
       "      <td>A105C_G196Q</td>\n",
       "      <td>9.361016</td>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alpha-A105C_L162Q</td>\n",
       "      <td>Alpha</td>\n",
       "      <td>A105C_L162Q</td>\n",
       "      <td>6.275086</td>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alpha-A105D</td>\n",
       "      <td>Alpha</td>\n",
       "      <td>A105D</td>\n",
       "      <td>7.315937</td>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alpha-A105D_L111G</td>\n",
       "      <td>Alpha</td>\n",
       "      <td>A105D_L111G</td>\n",
       "      <td>7.150618</td>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52758</th>\n",
       "      <td>Wuhan_Hu_1-Y93V_A145V</td>\n",
       "      <td>Wuhan_Hu_1</td>\n",
       "      <td>Y93V_A145V</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52759</th>\n",
       "      <td>Wuhan_Hu_1-Y93V_K128L</td>\n",
       "      <td>Wuhan_Hu_1</td>\n",
       "      <td>Y93V_K128L</td>\n",
       "      <td>5.827319</td>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52760</th>\n",
       "      <td>Wuhan_Hu_1-Y93V_N110I</td>\n",
       "      <td>Wuhan_Hu_1</td>\n",
       "      <td>Y93V_N110I</td>\n",
       "      <td>5.263860</td>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52761</th>\n",
       "      <td>Wuhan_Hu_1-Y93W</td>\n",
       "      <td>Wuhan_Hu_1</td>\n",
       "      <td>Y93W</td>\n",
       "      <td>5.293445</td>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52762</th>\n",
       "      <td>Wuhan_Hu_1-Y93W_F126E</td>\n",
       "      <td>Wuhan_Hu_1</td>\n",
       "      <td>Y93W_F126E</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52763 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       label      target aa_substitutions   log10Ka  \\\n",
       "0                Alpha-A105C       Alpha            A105C  9.086811   \n",
       "1          Alpha-A105C_G196Q       Alpha      A105C_G196Q  9.361016   \n",
       "2          Alpha-A105C_L162Q       Alpha      A105C_L162Q  6.275086   \n",
       "3                Alpha-A105D       Alpha            A105D  7.315937   \n",
       "4          Alpha-A105D_L111G       Alpha      A105D_L111G  7.150618   \n",
       "...                      ...         ...              ...       ...   \n",
       "52758  Wuhan_Hu_1-Y93V_A145V  Wuhan_Hu_1       Y93V_A145V  5.000000   \n",
       "52759  Wuhan_Hu_1-Y93V_K128L  Wuhan_Hu_1       Y93V_K128L  5.827319   \n",
       "52760  Wuhan_Hu_1-Y93V_N110I  Wuhan_Hu_1       Y93V_N110I  5.263860   \n",
       "52761        Wuhan_Hu_1-Y93W  Wuhan_Hu_1             Y93W  5.293445   \n",
       "52762  Wuhan_Hu_1-Y93W_F126E  Wuhan_Hu_1       Y93W_F126E  5.000000   \n",
       "\n",
       "                                                sequence  \n",
       "0      NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...  \n",
       "1      NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...  \n",
       "2      NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...  \n",
       "3      NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...  \n",
       "4      NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...  \n",
       "...                                                  ...  \n",
       "52758  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...  \n",
       "52759  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...  \n",
       "52760  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...  \n",
       "52761  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...  \n",
       "52762  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...  \n",
       "\n",
       "[52763 rows x 5 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to only the columns we want and copy the DataFrame to avoid SettingWithCopyWarning\n",
    "unique_filtered_df = merged_df[['label','target', 'aa_substitutions', 'log10Ka']].copy()\n",
    "\n",
    "# Utilize 'aa_substitutions' to generate the mutated sequence\n",
    "unique_filtered_df['sequence'] = unique_filtered_df.apply(label_to_seq, axis=1, target_refseqs=variants_target_refseqs)\n",
    "unique_filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final file pathing\n",
    "save_as = os.path.join(data_dir, 'processed_dms/mutation_variants-bc_binding.csv')\n",
    "\n",
    "# Select final columns \n",
    "final_df = unique_filtered_df[['label', 'target', 'log10Ka', 'sequence']].copy()\n",
    "\n",
    "# Save processed data to .csv\n",
    "final_df.to_csv(save_as, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run this process but on each of the other data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(target_refseqs, input_csv, output_csv):\n",
    "    \"\"\" \n",
    "    Process the DMS binding and expression datasets.\n",
    "    - Drop NAs\n",
    "    - Select only nonsynonymous variant classes\n",
    "    - Select unique nonsynonymous mutations\n",
    "        - For duplicate aa_substitutions, take the mean value of log10Ka or expression (expression?)\n",
    "    - Apply mutations to reference sequence\n",
    "    \"\"\"\n",
    "\n",
    "    if  \"binding\" in input_csv:\n",
    "        value_column = \"log10Ka\"\n",
    "        print(\"Looking at DMS binding dataset.\")\n",
    "    elif \"expression\" in input_csv:\n",
    "        value_column = \"expression\"\n",
    "        print(\"Looking at DMS expression dataset.\")\n",
    "\n",
    "    full_df = pd.read_csv(input_csv, sep=',', header=0)\n",
    "    row_count = len(full_df)\n",
    "    print(f\"Number of data points: {row_count}\")\n",
    "\n",
    "    rename_map = {\n",
    "    'N501Y': 'Alpha',\n",
    "    'B1351': 'Beta',\n",
    "    'Delta': 'Delta',\n",
    "    'E484K': 'Eta',\n",
    "    'BA1': 'Omicron_BA1',\n",
    "    'BA2': 'Omicron_BA2',\n",
    "    'BQ11': 'Omicron_BQ11',\n",
    "    'XBB15': 'Omicron_XBB15',\n",
    "    'Wuhan_Hu_1': 'Wuhan_Hu_1'\n",
    "    }\n",
    "    # Rename target columns for easier variant identification\n",
    "    full_df['target'] = full_df['target'].replace(rename_map)\n",
    "\n",
    "    # Remove rows where specified column is NA\n",
    "    full_df = full_df.dropna(subset=[value_column]).reset_index(drop=True)\n",
    "    print(f\"Number of data points with na: {row_count-len(full_df)}\")\n",
    "    print(f\"Number of data points left {len(full_df)}\")\n",
    "    \n",
    "    # Count number of entries per variant class\n",
    "    value_counts = full_df[\"variant_class\"].value_counts()\n",
    "    print(f\"{value_counts}\\n\")\n",
    "    # Filter out variant classes that are not nonsynonymous\n",
    "    nonsynonymous_df = full_df[full_df['variant_class'].str.contains('nonsynonymous', case=False, na=False)]\n",
    "    # Copy the DataFrame to avoid SettingWithCopyWarning\n",
    "    nonsynonymous_df = nonsynonymous_df.copy()\n",
    "\n",
    "    print(f\"Different variants/targets: {nonsynonymous_df['target'].unique()}\\n\")\n",
    "\n",
    "    # Add '_' to aa_substitutions column\n",
    "    nonsynonymous_df.loc[:, 'aa_substitutions'] = nonsynonymous_df['aa_substitutions'].replace(' ', '_', regex=True)\n",
    "    # Create a new column 'label' using 'target' and 'aa_substitutions' columns\n",
    "    nonsynonymous_df['label'] = nonsynonymous_df['target'] + '-' + nonsynonymous_df['aa_substitutions']\n",
    "    print(f\"{nonsynonymous_df['label'].value_counts()}\\n\")\n",
    "    # Group by 'label' and calculate the mean of the specified value column for each group\n",
    "    unique_nonsynonymous_df = nonsynonymous_df.groupby('label', as_index=False)[value_column].mean()\n",
    "    # Merge dfs, replace duplicate with average\n",
    "    merged_df = pd.merge(unique_nonsynonymous_df, nonsynonymous_df.drop(columns=value_column), on='label', how='left')\n",
    "    # Drop duplicate rows based on 'label'\n",
    "    merged_df = merged_df.drop_duplicates(subset='label').reset_index(drop=True)\n",
    "    # Count number of unique nonsynonymous mutations\n",
    "    unique_nonsynonymous_mutations_counts = merged_df['label'].nunique()\n",
    "    print(f\"Number of unique nonsynonymous mutations: {unique_nonsynonymous_mutations_counts}\")\n",
    "    \n",
    "    # Filter to only the columns we want and copy the DataFrame to avoid SettingWithCopyWarning\n",
    "    unique_filtered_df = merged_df[['label','target', 'aa_substitutions', value_column]].copy()\n",
    "    # Utilize 'aa_substitutions' to generate the mutated sequence\n",
    "    unique_filtered_df['sequence'] = unique_filtered_df.apply(label_to_seq, axis=1, target_refseqs=target_refseqs)\n",
    "\n",
    "    # Select final columns \n",
    "    final_df = unique_filtered_df[['label', 'target', value_column, 'sequence']].copy()\n",
    "    # Save processed data to .csv\n",
    "    final_df.to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wuhan_Hu_1: NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKST\n",
      "Beta: NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGNIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVKGFNCYFPLQSYGFQPTYGVGYQPYRVVVLSFELLHAPATVCGPKKST\n",
      "Eta: NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVKGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKST\n",
      "Alpha: NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTYGVGYQPYRVVVLSFELLHAPATVCGPKKST\n",
      "Delta: NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYRYRLFRKSNLKPFERDISTEIYQAGSKPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKST\n",
      "Omicron_BA1: NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNLAPFFTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGNIADYNYKLPDDFTGCVIAWNSNKLDSKVSGNYNYLYRLFRKSNLKPFERDISTEIYQAGNKPCNGVAGFNCYFPLRSYSFRPTYGVGHQPYRVVVLSFELLHAPATVCGPKKST\n",
      "Omicron_BA2: NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFAFKCYGVSPTKLNDLCFTNVYADSFVIRGNEVSQIAPGQTGNIADYNYKLPDDFTGCVIAWNSNKLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGNKPCNGVAGFNCYFPLRSYGFRPTYGVGHQPYRVVVLSFELLHAPATVCGPKKST\n",
      "Omicron_BQ11: NITNLCPFDEVFNATTFASVYAWNRKRISNCVADYSVLYNFAPFFAFKCYGVSPTKLNDLCFTNVYADSFVIRGNEVSQIAPGQTGNIADYNYKLPDDFTGCVIAWNSNKLDSTVGGNYNYRYRLFRKSKLKPFERDISTEIYQAGNKPCNGVAGVNCYFPLQSYGFRPTYGVGHQPYRVVVLSFELLHAPATVCGPKKST\n",
      "Omicron_XBB15: NITNLCPFHEVFNATTFASVYAWNRKRISNCVADYSVIYNFAPFFAFKCYGVSPTKLNDLCFTNVYADSFVIRGNEVSQIAPGQTGNIADYNYKLPDDFTGCVIAWNSNKLDSKPSGNYNYLYRLFRKSKLKPFERDISTEIYQAGNKPCNGVAGPNCYSPLQSYGFRPTYGVGHQPYRVVVLSFELLHAPATVCGPKKST\n"
     ]
    }
   ],
   "source": [
    "variants = ['Wuhan_Hu_1', 'B1351', 'E484K', 'N501Y', 'Delta', 'BA1', 'BA2', 'BQ11', 'XBB15']\n",
    "target_refseqs = extract_refseqs(variants)\n",
    "for t in target_refseqs: print(f\"{t}: {target_refseqs[t]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at DMS expression dataset.\n",
      "Number of data points: 337629\n",
      "Number of data points with na: 43311\n",
      "Number of data points left 294318\n",
      "variant_class\n",
      "1 nonsynonymous     178356\n",
      "wildtype             73795\n",
      ">1 nonsynonymous     40420\n",
      "synonymous             969\n",
      "stop                   778\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Different variants/targets: ['Wuhan_Hu_1' 'Beta' 'Eta' 'Alpha']\n",
      "\n",
      "label\n",
      "Eta-V115L                90\n",
      "Beta-V32L                88\n",
      "Eta-N171S                86\n",
      "Eta-V115S                70\n",
      "Eta-N171R                70\n",
      "                         ..\n",
      "Wuhan_Hu_1-G83M_S184K     1\n",
      "Wuhan_Hu_1-E10D_E76V      1\n",
      "Alpha-S43A_F160E          1\n",
      "Beta-D34R_F126W           1\n",
      "Alpha-P54D_L183H          1\n",
      "Name: count, Length: 54391, dtype: int64\n",
      "\n",
      "Number of unique nonsynonymous mutations: 54391\n"
     ]
    }
   ],
   "source": [
    "expression_csv = os.path.join(data_dir, 'original_dms/variants-bc_expression.csv')\n",
    "save_as = os.path.join(data_dir, 'processed_dms/mutation_variants-bc_expression.csv')\n",
    "process_data(target_refseqs, expression_csv, save_as)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at DMS binding dataset.\n",
      "Number of data points: 205734\n",
      "Number of data points with na: 23388\n",
      "Number of data points left 182346\n",
      "variant_class\n",
      "1 nonsynonymous     120999\n",
      "wildtype             36189\n",
      ">1 nonsynonymous     24853\n",
      "synonymous             305\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Different variants/targets: ['Delta']\n",
      "\n",
      "label\n",
      "Delta-N64W           70\n",
      "Delta-S45P           66\n",
      "Delta-K114W          62\n",
      "Delta-N110S          62\n",
      "Delta-E154Y          61\n",
      "                     ..\n",
      "Delta-T63K_K94M       1\n",
      "Delta-F126M_S139T     1\n",
      "Delta-Q79M_Q168H      1\n",
      "Delta-Y21C_K198C      1\n",
      "Delta-Y50R_R127P      1\n",
      "Name: count, Length: 27274, dtype: int64\n",
      "\n",
      "Number of unique nonsynonymous mutations: 27274\n"
     ]
    }
   ],
   "source": [
    "binding_csv = os.path.join(data_dir, 'original_dms/delta-bc_binding.csv')\n",
    "save_as = os.path.join(data_dir, 'processed_dms/mutation_delta-bc_binding.csv')\n",
    "process_data(target_refseqs, binding_csv, save_as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at DMS expression dataset.\n",
      "Number of data points: 205734\n",
      "Number of data points with na: 11573\n",
      "Number of data points left 194161\n",
      "variant_class\n",
      "1 nonsynonymous     127540\n",
      "wildtype             37693\n",
      ">1 nonsynonymous     26532\n",
      "stop                  2076\n",
      "synonymous             320\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Different variants/targets: ['Delta']\n",
      "\n",
      "label\n",
      "Delta-N64W               71\n",
      "Delta-S45P               69\n",
      "Delta-F70R               67\n",
      "Delta-K114W              64\n",
      "Delta-R136L              63\n",
      "                         ..\n",
      "Delta-A42S_N64W           1\n",
      "Delta-Y91D_Y165G          1\n",
      "Delta-K26Q_C49H_C158D     1\n",
      "Delta-A22K_S108F          1\n",
      "Delta-G86M_G146Y          1\n",
      "Name: count, Length: 28729, dtype: int64\n",
      "\n",
      "Number of unique nonsynonymous mutations: 28729\n"
     ]
    }
   ],
   "source": [
    "expression_csv = os.path.join(data_dir, 'original_dms/delta-bc_expression.csv')\n",
    "save_as = os.path.join(data_dir, 'processed_dms/mutation_delta-bc_expression.csv')\n",
    "process_data(target_refseqs, expression_csv, save_as)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Omicron Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at DMS binding dataset.\n",
      "Number of data points: 649481\n",
      "Number of data points with na: 308459\n",
      "Number of data points left 341022\n",
      "variant_class\n",
      "1 nonsynonymous     320786\n",
      ">1 nonsynonymous     10613\n",
      "wildtype              9269\n",
      "synonymous             354\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Different variants/targets: ['Omicron_XBB15' 'Omicron_BQ11' 'Omicron_BA2']\n",
      "\n",
      "label\n",
      "Omicron_XBB15-Y121S          103\n",
      "Omicron_XBB15-Y121R           87\n",
      "Omicron_XBB15-V180-           82\n",
      "Omicron_BQ11-P149S            78\n",
      "Omicron_XBB15-Y121T           77\n",
      "                            ... \n",
      "Omicron_BA2-R179K_T201Q        1\n",
      "Omicron_BQ11-A14T_I80M         1\n",
      "Omicron_XBB15-R73F_A81S        1\n",
      "Omicron_BA2-K48S_V52F          1\n",
      "Omicron_XBB15-Y119F_R124T      1\n",
      "Name: count, Length: 21653, dtype: int64\n",
      "\n",
      "Number of unique nonsynonymous mutations: 21653\n"
     ]
    }
   ],
   "source": [
    "binding_csv = os.path.join(data_dir, 'original_dms/omicron_BA-bc_binding.csv')\n",
    "save_as = os.path.join(data_dir, 'processed_dms/mutation_omicron_BA-bc_binding.csv')\n",
    "process_data(target_refseqs, binding_csv, save_as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at DMS expression dataset.\n",
      "Number of data points: 598394\n",
      "Number of data points with na: 97861\n",
      "Number of data points left 500533\n",
      "variant_class\n",
      "1 nonsynonymous     446359\n",
      "wildtype             25152\n",
      ">1 nonsynonymous     23048\n",
      "stop                  5659\n",
      "synonymous             315\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Different variants/targets: ['Wuhan_Hu_1' 'Omicron_BA1' 'Omicron_BA2']\n",
      "\n",
      "label\n",
      "Omicron_BA1-S19W           119\n",
      "Omicron_BA1-Y50G           116\n",
      "Omicron_BA1-A18W           112\n",
      "Omicron_BA1-A18Y           112\n",
      "Omicron_BA1-S19G           111\n",
      "                          ... \n",
      "Omicron_BA1-R27M_D137A       1\n",
      "Wuhan_Hu_1-S45R_V52P         1\n",
      "Wuhan_Hu_1-V11Q_S200Q        1\n",
      "Omicron_BA2-E135N_G172S      1\n",
      "Omicron_BA2-D68W_C158Y       1\n",
      "Name: count, Length: 32663, dtype: int64\n",
      "\n",
      "Number of unique nonsynonymous mutations: 32663\n"
     ]
    }
   ],
   "source": [
    "expression_csv = os.path.join(data_dir, 'original_dms/omicron_BA-bc_expression.csv')\n",
    "save_as = os.path.join(data_dir, 'processed_dms/mutation_omicron_BA-bc_expression.csv')\n",
    "process_data(target_refseqs, expression_csv, save_as)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd Omicron Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at DMS binding dataset.\n",
      "Number of data points: 598394\n",
      "Number of data points with na: 163488\n",
      "Number of data points left 434906\n",
      "variant_class\n",
      "1 nonsynonymous     386015\n",
      "wildtype             27387\n",
      ">1 nonsynonymous     21159\n",
      "synonymous             345\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Different variants/targets: ['Wuhan_Hu_1' 'Omicron_BA1' 'Omicron_BA2']\n",
      "\n",
      "label\n",
      "Omicron_BA1-S19W          99\n",
      "Omicron_BA1-A18Y          98\n",
      "Omicron_BA1-A18W          97\n",
      "Omicron_BA1-A18E          94\n",
      "Omicron_BA1-Y66W          93\n",
      "                          ..\n",
      "Wuhan_Hu_1-F12G_E154H      1\n",
      "Omicron_BA2-G51A_L111F     1\n",
      "Omicron_BA1-D59Y_D68K      1\n",
      "Omicron_BA1-A89S_A154Y     1\n",
      "Omicron_BA2-D68W_C158Y     1\n",
      "Name: count, Length: 31244, dtype: int64\n",
      "\n",
      "Number of unique nonsynonymous mutations: 31244\n"
     ]
    }
   ],
   "source": [
    "binding_csv = os.path.join(data_dir, 'original_dms/omicron_XBB_BQ-bc_binding.csv')\n",
    "save_as = os.path.join(data_dir, 'processed_dms/mutation_omicron_XBB_BQ-bc_binding.csv')\n",
    "process_data(target_refseqs, binding_csv, save_as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at DMS expression dataset.\n",
      "Number of data points: 649481\n",
      "Number of data points with na: 244004\n",
      "Number of data points left 405477\n",
      "variant_class\n",
      "1 nonsynonymous     375709\n",
      ">1 nonsynonymous     13002\n",
      "wildtype             11322\n",
      "stop                  4990\n",
      "synonymous             454\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Different variants/targets: ['Omicron_XBB15' 'Omicron_BQ11' 'Omicron_BA2']\n",
      "\n",
      "label\n",
      "Omicron_XBB15-V180-          116\n",
      "Omicron_XBB15-Y121S          112\n",
      "Omicron_XBB15-Y121R           91\n",
      "Omicron_BQ11-P149S            84\n",
      "Omicron_XBB15-Y121T           75\n",
      "                            ... \n",
      "Omicron_XBB15-K132-_E141G      1\n",
      "Omicron_BQ11-F70L_S139C        1\n",
      "Omicron_BA2-A22K_W23L          1\n",
      "Omicron_XBB15-K94E_I138V       1\n",
      "Omicron_XBB15-Y119F_R124T      1\n",
      "Name: count, Length: 23680, dtype: int64\n",
      "\n",
      "Number of unique nonsynonymous mutations: 23680\n"
     ]
    }
   ],
   "source": [
    "expression_csv = os.path.join(data_dir, 'original_dms/omicron_XBB_BQ-bc_expression.csv')\n",
    "save_as = os.path.join(data_dir, 'processed_dms/mutation_omicron_XBB_BQ-bc_expression.csv')\n",
    "process_data(target_refseqs, expression_csv, save_as)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Combination of Variant Datasets\n",
    "\n",
    "Let's combine all expression and all binding data into 2 big files so we can put them in the ESM-BLSTM model. Get rid of all Wuhan variants. We'll add a column that represents the variant.\n",
    "\n",
    "### Binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta binding # entries: 27274\n",
      "Delta binding # entries, no wuhan: 27274\n",
      "Number of duplicates: 0\n",
      "\n",
      "Omicron1 binding # entries: 21653\n",
      "Omicron1 binding # entries, no wuhan: 21653\n",
      "Number of duplicates: 0\n",
      "\n",
      "Omicron2 binding # entries: 31244\n",
      "Omicron2 binding # entries, no wuhan: 17352\n",
      "Number of duplicates: 0\n",
      "\n",
      "Alpha, beta, eta # entries: 52763\n",
      "Alpha, beta, eta # entries, no wuhan: 39314\n",
      "Number of duplicates: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delta_binding_df = pd.read_csv(os.path.join(data_dir, \"processed_dms/mutation_delta-bc_binding.csv\"), sep=',', header=0)\n",
    "print(f\"Delta binding # entries: {len(delta_binding_df)}\")\n",
    "delta_binding_df = delta_binding_df[delta_binding_df['target'] != 'Wuhan_Hu_1']\n",
    "print(f\"Delta binding # entries, no wuhan: {len(delta_binding_df)}\")\n",
    "print(f\"Number of duplicates: {len(delta_binding_df[delta_binding_df.duplicated(subset=['label'], keep=False)])}\\n\")\n",
    "\n",
    "omicron1_binding_df = pd.read_csv(os.path.join(data_dir, \"processed_dms/mutation_omicron_BA-bc_binding.csv\"), sep=',', header=0)\n",
    "print(f\"Omicron1 binding # entries: {len(omicron1_binding_df)}\")\n",
    "omicron1_binding_df = omicron1_binding_df[omicron1_binding_df['target'] != 'Wuhan_Hu_1']\n",
    "print(f\"Omicron1 binding # entries, no wuhan: {len(omicron1_binding_df)}\")\n",
    "print(f\"Number of duplicates: {len(omicron1_binding_df[omicron1_binding_df.duplicated(subset=['label'], keep=False)])}\\n\")\n",
    "\n",
    "omicron2_binding_df = pd.read_csv(os.path.join(data_dir, \"processed_dms/mutation_omicron_XBB_BQ-bc_binding.csv\"), sep=',', header=0)\n",
    "print(f\"Omicron2 binding # entries: {len(omicron2_binding_df)}\")\n",
    "omicron2_binding_df = omicron2_binding_df[omicron2_binding_df['target'] != 'Wuhan_Hu_1']\n",
    "print(f\"Omicron2 binding # entries, no wuhan: {len(omicron2_binding_df)}\")\n",
    "print(f\"Number of duplicates: {len(omicron2_binding_df[omicron2_binding_df.duplicated(subset=['label'], keep=False)])}\\n\")\n",
    "\n",
    "alpha_beta_eta_binding_df = pd.read_csv(os.path.join(data_dir, \"processed_dms/mutation_variants-bc_binding.csv\"), sep=',', header=0)\n",
    "print(f\"Alpha, beta, eta # entries: {len(alpha_beta_eta_binding_df)}\")\n",
    "alpha_beta_eta_binding_df = alpha_beta_eta_binding_df[alpha_beta_eta_binding_df['target'] != 'Wuhan_Hu_1']\n",
    "print(f\"Alpha, beta, eta # entries, no wuhan: {len(alpha_beta_eta_binding_df)}\")\n",
    "print(f\"Number of duplicates: {len(alpha_beta_eta_binding_df[alpha_beta_eta_binding_df.duplicated(subset=['label'], keep=False)])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of combined entries: 105593\n",
      "Number of entries with duplicates (all copies): 14192\n",
      "Number of entries with no duplicates: 91401\n",
      "Number of deduplicated entries: 7096\n",
      "New number of entries with no duplicates: 98497\n",
      "Confirm successful deduplication?: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sequence</th>\n",
       "      <th>log10Ka</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Omicron_BA2-A105C</td>\n",
       "      <td>NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>8.783580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Omicron_BA2-A105D</td>\n",
       "      <td>NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>6.315664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Omicron_BA2-A105D_G196S</td>\n",
       "      <td>NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>6.727197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Omicron_BA2-A105D_N147M</td>\n",
       "      <td>NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>5.653277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Omicron_BA2-A105D_S108I</td>\n",
       "      <td>NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>6.083346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98492</th>\n",
       "      <td>Eta-Y93T</td>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "      <td>5.892614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98493</th>\n",
       "      <td>Eta-Y93V</td>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "      <td>5.776665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98494</th>\n",
       "      <td>Eta-Y93V_L122Y</td>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98495</th>\n",
       "      <td>Eta-Y93W</td>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "      <td>5.639833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98496</th>\n",
       "      <td>Eta-Y93W_V103L</td>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "      <td>5.438558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98497 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         label  \\\n",
       "0            Omicron_BA2-A105C   \n",
       "1            Omicron_BA2-A105D   \n",
       "2      Omicron_BA2-A105D_G196S   \n",
       "3      Omicron_BA2-A105D_N147M   \n",
       "4      Omicron_BA2-A105D_S108I   \n",
       "...                        ...   \n",
       "98492                 Eta-Y93T   \n",
       "98493                 Eta-Y93V   \n",
       "98494           Eta-Y93V_L122Y   \n",
       "98495                 Eta-Y93W   \n",
       "98496           Eta-Y93W_V103L   \n",
       "\n",
       "                                                sequence   log10Ka  \n",
       "0      NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...  8.783580  \n",
       "1      NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...  6.315664  \n",
       "2      NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...  6.727197  \n",
       "3      NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...  5.653277  \n",
       "4      NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...  6.083346  \n",
       "...                                                  ...       ...  \n",
       "98492  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...  5.892614  \n",
       "98493  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...  5.776665  \n",
       "98494  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...  5.000000  \n",
       "98495  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...  5.639833  \n",
       "98496  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...  5.438558  \n",
       "\n",
       "[98497 rows x 3 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combination\n",
    "combined_binding_df = pd.concat([delta_binding_df, omicron2_binding_df, omicron1_binding_df, alpha_beta_eta_binding_df], ignore_index=True)\n",
    "combined_binding_df = combined_binding_df[['label', 'log10Ka', 'sequence']]\n",
    "print(f\"Total number of combined entries: {len(combined_binding_df)}\")\n",
    "\n",
    "# Identify all duplicate entries based on certain columns, including the original entries\n",
    "duplicated_df = combined_binding_df[combined_binding_df.duplicated(subset=['label', 'sequence'], keep=False)]\n",
    "print(f\"Number of entries with duplicates (all copies): {len(duplicated_df)}\")\n",
    "\n",
    "# Filter out these duplicate entries from the combined df\n",
    "filtered_df = combined_binding_df[~combined_binding_df['label'].isin(duplicated_df['label'])].reset_index(drop=True)\n",
    "print(f\"Number of entries with no duplicates: {len(filtered_df)}\")\n",
    "\n",
    "# Group by 'label' and 'sequence', and calculate the mean of the specified value column for each group\n",
    "deduplicated_df = duplicated_df.groupby(['label', 'sequence'], as_index=False)[\"log10Ka\"].mean()\n",
    "print(f\"Number of deduplicated entries: {len(deduplicated_df)}\")\n",
    "\n",
    "# Combine the deduplicated df and filtered df\n",
    "combined_binding_df = pd.concat([deduplicated_df, filtered_df], ignore_index=True)\n",
    "print(f\"New number of entries with no duplicates: {len(combined_binding_df)}\")\n",
    "\n",
    "# Check to see if duplicates were removed:\n",
    "print(f\"Confirm successful deduplication?: {len(combined_binding_df[combined_binding_df.duplicated(subset=['label', 'sequence'], keep=False)])}\")\n",
    "\n",
    "# Save\n",
    "combined_binding_df.to_csv(os.path.join(data_dir, 'processed_dms/mutation_combined_binding.csv'), index=False)\n",
    "combined_binding_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta expression # entries: 28729\n",
      "Delta expression # entries, no wuhan: 28729\n",
      "Number of duplicates: 0\n",
      "\n",
      "Omicron1 expression # entries: 32663\n",
      "Omicron1 expression # entries, no wuhan: 19032\n",
      "Number of duplicates: 0\n",
      "\n",
      "Omicron2 expression # entries: 23680\n",
      "Omicron2 expression # entries, no wuhan: 23680\n",
      "Number of duplicates: 0\n",
      "\n",
      "Alpha, beta, eta # entries: 54391\n",
      "Alpha, beta, eta # entries, no wuhan: 40780\n",
      "Number of duplicates: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delta_expression_df = pd.read_csv(os.path.join(data_dir, \"processed_dms/mutation_delta-bc_expression.csv\"), sep=',', header=0)\n",
    "print(f\"Delta expression # entries: {len(delta_expression_df)}\")\n",
    "delta_expression_df = delta_expression_df[delta_expression_df['target'] != 'Wuhan_Hu_1']\n",
    "print(f\"Delta expression # entries, no wuhan: {len(delta_expression_df)}\")\n",
    "print(f\"Number of duplicates: {len(delta_expression_df[delta_expression_df.duplicated(subset=['label'], keep=False)])}\\n\")\n",
    "\n",
    "omicron1_expression_df = pd.read_csv(os.path.join(data_dir, \"processed_dms/mutation_omicron_BA-bc_expression.csv\"), sep=',', header=0)\n",
    "print(f\"Omicron1 expression # entries: {len(omicron1_expression_df)}\")\n",
    "omicron1_expression_df = omicron1_expression_df[omicron1_expression_df['target'] != 'Wuhan_Hu_1']\n",
    "print(f\"Omicron1 expression # entries, no wuhan: {len(omicron1_expression_df)}\")\n",
    "print(f\"Number of duplicates: {len(omicron1_expression_df[omicron1_expression_df.duplicated(subset=['label'], keep=False)])}\\n\")\n",
    "\n",
    "omicron2_expression_df = pd.read_csv(os.path.join(data_dir, \"processed_dms/mutation_omicron_XBB_BQ-bc_expression.csv\"), sep=',', header=0)\n",
    "print(f\"Omicron2 expression # entries: {len(omicron2_expression_df)}\")\n",
    "omicron2_expression_df = omicron2_expression_df[omicron2_expression_df['target'] != 'Wuhan_Hu_1']\n",
    "print(f\"Omicron2 expression # entries, no wuhan: {len(omicron2_expression_df)}\")\n",
    "print(f\"Number of duplicates: {len(omicron2_expression_df[omicron2_expression_df.duplicated(subset=['label'], keep=False)])}\\n\")\n",
    "\n",
    "alpha_beta_eta_expression_df = pd.read_csv(os.path.join(data_dir, \"processed_dms/mutation_variants-bc_expression.csv\"), sep=',', header=0)\n",
    "print(f\"Alpha, beta, eta # entries: {len(alpha_beta_eta_expression_df)}\")\n",
    "alpha_beta_eta_expression_df = alpha_beta_eta_expression_df[alpha_beta_eta_expression_df['target'] != 'Wuhan_Hu_1']\n",
    "print(f\"Alpha, beta, eta # entries, no wuhan: {len(alpha_beta_eta_expression_df)}\")\n",
    "print(f\"Number of duplicates: {len(alpha_beta_eta_expression_df[alpha_beta_eta_expression_df.duplicated(subset=['label'], keep=False)])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of combined entries: 112221\n",
      "Number of entries with duplicates (all copies): 16240\n",
      "Number of entries with no duplicates: 95981\n",
      "Number of deduplicated entries: 8120\n",
      "New number of entries with no duplicates: 104101\n",
      "Confirm successful deduplication?: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sequence</th>\n",
       "      <th>expression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Omicron_BA2-A105C</td>\n",
       "      <td>NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>7.975114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Omicron_BA2-A105D</td>\n",
       "      <td>NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>7.356103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Omicron_BA2-A105D_G196S</td>\n",
       "      <td>NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>6.784158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Omicron_BA2-A105D_K114D</td>\n",
       "      <td>NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>7.497698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Omicron_BA2-A105D_K114W</td>\n",
       "      <td>NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>7.589814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104096</th>\n",
       "      <td>Eta-Y93T</td>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "      <td>7.287253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104097</th>\n",
       "      <td>Eta-Y93V</td>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "      <td>7.620438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104098</th>\n",
       "      <td>Eta-Y93V_L122Y</td>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "      <td>7.187713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104099</th>\n",
       "      <td>Eta-Y93W</td>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "      <td>7.246666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104100</th>\n",
       "      <td>Eta-Y93W_V103L</td>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "      <td>7.050741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104101 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          label  \\\n",
       "0             Omicron_BA2-A105C   \n",
       "1             Omicron_BA2-A105D   \n",
       "2       Omicron_BA2-A105D_G196S   \n",
       "3       Omicron_BA2-A105D_K114D   \n",
       "4       Omicron_BA2-A105D_K114W   \n",
       "...                         ...   \n",
       "104096                 Eta-Y93T   \n",
       "104097                 Eta-Y93V   \n",
       "104098           Eta-Y93V_L122Y   \n",
       "104099                 Eta-Y93W   \n",
       "104100           Eta-Y93W_V103L   \n",
       "\n",
       "                                                 sequence  expression  \n",
       "0       NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...    7.975114  \n",
       "1       NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...    7.356103  \n",
       "2       NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...    6.784158  \n",
       "3       NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...    7.497698  \n",
       "4       NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...    7.589814  \n",
       "...                                                   ...         ...  \n",
       "104096  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...    7.287253  \n",
       "104097  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...    7.620438  \n",
       "104098  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...    7.187713  \n",
       "104099  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...    7.246666  \n",
       "104100  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...    7.050741  \n",
       "\n",
       "[104101 rows x 3 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combination\n",
    "combined_expression_df = pd.concat([delta_expression_df, omicron2_expression_df, omicron1_expression_df, alpha_beta_eta_expression_df], ignore_index=True)\n",
    "combined_expression_df = combined_expression_df[['label', 'expression', 'sequence']]\n",
    "print(f\"Total number of combined entries: {len(combined_expression_df)}\")\n",
    "\n",
    "# Identify all duplicate entries based on certain columns, including the original entries\n",
    "duplicated_df = combined_expression_df[combined_expression_df.duplicated(subset=['label', 'sequence'], keep=False)]\n",
    "print(f\"Number of entries with duplicates (all copies): {len(duplicated_df)}\")\n",
    "\n",
    "# Filter out these duplicate entries from the combined df\n",
    "filtered_df = combined_expression_df[~combined_expression_df['label'].isin(duplicated_df['label'])].reset_index(drop=True)\n",
    "print(f\"Number of entries with no duplicates: {len(filtered_df)}\")\n",
    "\n",
    "# Group by 'label' and 'sequence', and calculate the mean of the specified value column for each group\n",
    "deduplicated_df = duplicated_df.groupby(['label', 'sequence'], as_index=False)[\"expression\"].mean()\n",
    "print(f\"Number of deduplicated entries: {len(deduplicated_df)}\")\n",
    "\n",
    "# Combine the deduplicated df and filtered df\n",
    "combined_expression_df = pd.concat([deduplicated_df, filtered_df], ignore_index=True)\n",
    "print(f\"New number of entries with no duplicates: {len(combined_expression_df)}\")\n",
    "\n",
    "# Check to see if duplicates were removed:\n",
    "print(f\"Confirm successful deduplication?: {len(combined_expression_df[combined_expression_df.duplicated(subset=['label', 'sequence'], keep=False)])}\")\n",
    "\n",
    "# Save\n",
    "combined_expression_df.to_csv(os.path.join(data_dir, 'processed_dms/mutation_combined_expression.csv'), index=False)\n",
    "combined_expression_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data for training/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "def split_csv(rnd_seed: int, input_csv: str, output_csv:str):\n",
    "    \"\"\"\n",
    "    Split csv file into train, test data.\n",
    "    \"\"\"\n",
    "    train_csv = output_csv.replace('.csv', '_train.csv')\n",
    "    test_csv  = output_csv.replace('.csv', '_test.csv')\n",
    "\n",
    "    with open(input_csv, \"r\") as input_file:\n",
    "        reader = csv.reader(input_file)\n",
    "        header = next(reader)\n",
    "        input_records = list(reader)\n",
    "\n",
    "    random.seed(rnd_seed)\n",
    "    random.shuffle(input_records)\n",
    "\n",
    "    split_idx = int(0.8 * len(input_records))\n",
    "    train_records = input_records[:split_idx]\n",
    "    test_records = input_records[split_idx:]\n",
    "\n",
    "    with open(train_csv, 'w') as ft, open(test_csv, 'w') as fv:\n",
    "        train_writer = csv.writer(ft)\n",
    "        test_writer = csv.writer(fv)\n",
    "\n",
    "        train_writer.writerow(header)\n",
    "        test_writer.writerow(header)\n",
    "\n",
    "        for record in train_records:\n",
    "            train_writer.writerow(record)\n",
    "\n",
    "        for record in test_records:\n",
    "            test_writer.writerow(record)\n",
    "\n",
    "    print(f'Total: {len(input_records)}, Train: {len(train_records)}, Test: {len(test_records)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 98497, Train: 78797, Test: 19700\n",
      "Total: 104101, Train: 83280, Test: 20821\n"
     ]
    }
   ],
   "source": [
    "# Split to train, test data (80/20)\n",
    "rnd_seed = 0\n",
    "\n",
    "combined_binding_csv = 'mutation_combined_binding.csv'\n",
    "split_csv(\n",
    "    rnd_seed, \n",
    "    os.path.join(data_dir, f'processed_dms/{combined_binding_csv}'), \n",
    "    os.path.join(data_dir, f'split_processed_dms/{combined_binding_csv}')\n",
    ")\n",
    "\n",
    "combined_expression_csv = 'mutation_combined_expression.csv'\n",
    "split_csv(\n",
    "    rnd_seed, \n",
    "    os.path.join(data_dir, f'processed_dms/{combined_expression_csv}'), \n",
    "    os.path.join(data_dir, f'split_processed_dms/{combined_expression_csv}')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spike_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
